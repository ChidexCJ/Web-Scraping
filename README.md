# Overview
The objective of this project is to develop a web scraping process.
# Stack
- Python
- BeautifulSoup
- Requests
- Pandas
## Creation of a project directory and a new virtual virtual environment.
The purpose of this exercise is to create a separate folder for every file attached to this project and to avoid using a cluttered environment for the installation of dependencies. A run through the processes:

- launching the command prompt on the windows device and running the following commands
- mkdir ***name*** this creates a new project directory
- CD ***name*** this opens the directory
- pip install virtualenv this installs a new environment into the directory
- python -m venv ***name_of_environment*** this initialises the virtual environment
- ***name_of_environment***\Scripts\activate.bat this activates the virtual environment
pip intall (dependencies)
# SCRAPING PROCESS
# ![Procedure](https://github.com/ChidexCJ/Web-Scraping/blob/main/WEBSCRAPE.png)
1. **URL**: This is the web address associated to the search term whose data is to be pulled.
2. **Requests**: A python library for making HTTP GET requests from web services, this pulls data from the URL.
3. **BeautifulSoup**: This python library is used for extracting data from HTML and XML files.
4. **Pandas**: For creating and manipulating dataframes.

# Summary
Following the steps as outlined above, with careful attention to each stack documentation and web HTML/XML structure, data sourcing is just a click away. :wink:
